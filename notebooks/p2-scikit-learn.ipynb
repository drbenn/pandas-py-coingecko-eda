{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Crypto Market Intelligence System\n",
    "# Full ML Pipeline: Data → Features → Models → Evaluation\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: SETUP & DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 2: CRYPTO MARKET INTELLIGENCE SYSTEM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: DATA COLLECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[1] FETCHING DATA FROM COINGECKO...\")\n",
    "\n",
    "url = \"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart\"\n",
    "params = {\n",
    "    'vs_currency': 'usd',\n",
    "    'days': '365',\n",
    "    'interval': 'daily'\n",
    "}\n",
    "\n",
    "r = requests.get(url, params=params)\n",
    "data = r.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "prices = pd.DataFrame(data['prices'], columns=['timestamp', 'price'])\n",
    "volumes = pd.DataFrame(data['total_volumes'], columns=['timestamp', 'volume'])\n",
    "\n",
    "# Merge price and volume\n",
    "df = prices.merge(volumes, on='timestamp')\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df = df.drop('timestamp', axis=1)\n",
    "\n",
    "print(f\"✓ Loaded {len(df)} days of Bitcoin data\")\n",
    "print(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"\\nFirst few rows:\\n{df.head()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[2] FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Make a copy to work with\n",
    "df_features = df.copy()\n",
    "df_features = df_features.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# --- PRICE-BASED FEATURES ---\n",
    "print(\"\\n[Price-Based Features]\")\n",
    "\n",
    "# Daily returns (% change in price)\n",
    "df_features['daily_return'] = df_features['price'].pct_change()\n",
    "print(\"  ✓ Daily return\")\n",
    "\n",
    "# Price momentum (% change over 5 days, 10 days)\n",
    "df_features['momentum_5d'] = df_features['price'].pct_change(5)\n",
    "df_features['momentum_10d'] = df_features['price'].pct_change(10)\n",
    "print(\"  ✓ Momentum (5d, 10d)\")\n",
    "\n",
    "# Rolling volatility (standard deviation of returns over 30 days)\n",
    "df_features['volatility_30d'] = df_features['daily_return'].rolling(30).std()\n",
    "print(\"  ✓ Volatility (30d rolling)\")\n",
    "\n",
    "# Price range (high-low as % of close)\n",
    "df_features['price_range'] = (df_features['price'].rolling(20).max() - \n",
    "                              df_features['price'].rolling(20).min()) / df_features['price']\n",
    "print(\"  ✓ Price range (20d)\")\n",
    "\n",
    "# --- TECHNICAL INDICATORS (using TA library) ---\n",
    "print(\"\\n[Technical Indicators]\")\n",
    "\n",
    "# Simple Moving Average (SMA) - smooths price trend\n",
    "df_features['sma_20'] = ta.trend.sma_indicator(df_features['price'], window=20)\n",
    "df_features['sma_50'] = ta.trend.sma_indicator(df_features['price'], window=50)\n",
    "print(\"  ✓ SMA (20, 50)\")\n",
    "\n",
    "# Exponential Moving Average (EMA) - gives more weight to recent prices\n",
    "df_features['ema_12'] = ta.trend.ema_indicator(df_features['price'], window=12)\n",
    "df_features['ema_26'] = ta.trend.ema_indicator(df_features['price'], window=26)\n",
    "print(\"  ✓ EMA (12, 26)\")\n",
    "\n",
    "# MACD (Moving Average Convergence Divergence) - momentum indicator\n",
    "macd_line = ta.trend.macd(df_features['price'])\n",
    "df_features['macd'] = macd_line\n",
    "print(\"  ✓ MACD\")\n",
    "\n",
    "# RSI (Relative Strength Index) - measures overbought/oversold (0-100)\n",
    "df_features['rsi_14'] = ta.momentum.rsi(df_features['price'], window=14)\n",
    "print(\"  ✓ RSI (14)\")\n",
    "\n",
    "# Bollinger Bands (upper, lower bands + %B)\n",
    "bb = ta.volatility.BollingerBands(df_features['price'], window=20, window_dev=2)\n",
    "df_features['bb_upper'] = bb.bollinger_hband()\n",
    "df_features['bb_lower'] = bb.bollinger_lband()\n",
    "df_features['bb_pct'] = bb.bollinger_pband()  # % between bands\n",
    "print(\"  ✓ Bollinger Bands\")\n",
    "\n",
    "# --- VOLUME-BASED FEATURES ---\n",
    "print(\"\\n[Volume-Based Features]\")\n",
    "\n",
    "# Volume ratio (current vs average)\n",
    "df_features['volume_ratio'] = df_features['volume'] / df_features['volume'].rolling(20).mean()\n",
    "print(\"  ✓ Volume ratio\")\n",
    "\n",
    "# Price-Volume Trend (shows relationship between price and volume)\n",
    "df_features['pvt'] = ta.volume.money_flow_index(df_features['price'], df_features['volume'], window=14)\n",
    "print(\"  ✓ Price-Volume Trend (Money Flow Index)\")\n",
    "\n",
    "# --- DERIVED FEATURES ---\n",
    "print(\"\\n[Derived Features]\")\n",
    "\n",
    "# Price position relative to SMA (how far from trend)\n",
    "df_features['price_to_sma20'] = df_features['price'] / df_features['sma_20']\n",
    "df_features['price_to_sma50'] = df_features['price'] / df_features['sma_50']\n",
    "print(\"  ✓ Price to SMA ratios\")\n",
    "\n",
    "# EMA crossover signal (bullish when EMA12 > EMA26)\n",
    "df_features['ema_signal'] = (df_features['ema_12'] > df_features['ema_26']).astype(int)\n",
    "print(\"  ✓ EMA crossover signal\")\n",
    "\n",
    "# Remove rows with NaN values (from rolling/indicator calculations)\n",
    "initial_rows = len(df_features)\n",
    "df_features = df_features.dropna()\n",
    "removed_rows = initial_rows - len(df_features)\n",
    "print(f\"\\nRemoved {removed_rows} rows with NaN values (technical indicators need historical data)\")\n",
    "print(f\"Final dataset: {len(df_features)} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: TARGET VARIABLE CREATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[3] TARGET VARIABLE CREATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# REGRESSION TARGET: Predict tomorrow's price\n",
    "df_features['target_price_tomorrow'] = df_features['price'].shift(-1)\n",
    "\n",
    "# CLASSIFICATION TARGET: Predict up/down movement\n",
    "# 1 = price goes up tomorrow, 0 = price goes down or stays same\n",
    "df_features['target_direction'] = (df_features['price'].shift(-1) > df_features['price']).astype(int)\n",
    "\n",
    "# Remove last row (no target for final day)\n",
    "df_features = df_features[:-1].reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Regression target: next day's price\")\n",
    "print(f\"✓ Classification target: up (1) or down (0)\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Up days: {df_features['target_direction'].sum()} ({df_features['target_direction'].mean():.1%})\")\n",
    "print(f\"  Down days: {(1-df_features['target_direction']).sum()} ({(1-df_features['target_direction']).mean():.1%})\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: EXPLORATORY DATA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[4] FEATURE CORRELATION & ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select key features for correlation analysis\n",
    "key_features = [\n",
    "    'price', 'daily_return', 'volatility_30d', 'sma_20', 'rsi_14', \n",
    "    'volume_ratio', 'pvt', 'target_price_tomorrow'\n",
    "]\n",
    "\n",
    "correlation_matrix = df_features[key_features].corr()\n",
    "print(\"\\nFeature Correlations with Target Price:\")\n",
    "print(correlation_matrix['target_price_tomorrow'].sort_values(ascending=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: DATA PREPARATION FOR MODELING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[5] DATA PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select features (exclude price, date, and targets)\n",
    "feature_cols = [col for col in df_features.columns \n",
    "                if col not in ['date', 'price', 'volume', 'target_price_tomorrow', 'target_direction']]\n",
    "\n",
    "X = df_features[feature_cols].copy()\n",
    "y_regression = df_features['target_price_tomorrow'].copy()\n",
    "y_classification = df_features['target_direction'].copy()\n",
    "\n",
    "print(f\"\\n✓ Selected {len(feature_cols)} features for modeling\")\n",
    "print(f\"  Features: {', '.join(feature_cols[:5])}... (showing first 5)\")\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(\n",
    "    X, y_regression, y_classification, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-test split (80-20):\")\n",
    "print(f\"  Training set: {len(X_train)} samples\")\n",
    "print(f\"  Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Scale features (important for linear models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n✓ Features scaled using StandardScaler\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 7: REGRESSION MODELS (Price Prediction)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[6] REGRESSION MODELS - PREDICTING NEXT DAY'S PRICE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_reg_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_mse = mean_squared_error(y_reg_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_reg_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mae = mean_absolute_error(y_reg_test, y_pred_test)\n",
    "    test_r2 = r2_score(y_reg_test, y_pred_test)\n",
    "    \n",
    "    regression_results[name] = {\n",
    "        'model': model,\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train MSE: {train_mse:.2f}\")\n",
    "    print(f\"  Test RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"  Test MAE: ${test_mae:.2f}\")\n",
    "    print(f\"  Test R²: {test_r2:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 8: CLASSIFICATION MODELS (Up/Down Prediction)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[7] CLASSIFICATION MODELS - PREDICTING UP/DOWN MOVEMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "classification_results = {}\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_clf_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_clf_test, y_pred_test)\n",
    "    precision = precision_score(y_clf_test, y_pred_test)\n",
    "    recall = recall_score(y_clf_test, y_pred_test)\n",
    "    f1 = f1_score(y_clf_test, y_pred_test)\n",
    "    roc_auc = roc_auc_score(y_clf_test, y_pred_proba)\n",
    "    \n",
    "    classification_results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 9: MODEL COMPARISON & VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[8] MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Regression comparison\n",
    "print(\"\\nREGRESSION MODELS COMPARISON:\")\n",
    "reg_comparison = pd.DataFrame(regression_results).T[['test_rmse', 'test_mae', 'test_r2']]\n",
    "reg_comparison = reg_comparison.sort_values('test_rmse')\n",
    "print(reg_comparison)\n",
    "\n",
    "# Classification comparison\n",
    "print(\"\\nCLASSIFICATION MODELS COMPARISON:\")\n",
    "clf_comparison = pd.DataFrame(classification_results).T[['accuracy', 'precision', 'recall', 'f1', 'roc_auc']]\n",
    "clf_comparison = clf_comparison.sort_values('roc_auc', ascending=False)\n",
    "print(clf_comparison)\n",
    "\n",
    "# Visualization: Model Performance Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Regression\n",
    "reg_names = list(regression_results.keys())\n",
    "reg_rmse = [regression_results[m]['test_rmse'] for m in reg_names]\n",
    "axes[0].barh(reg_names, reg_rmse, color='steelblue')\n",
    "axes[0].set_xlabel('RMSE (Lower is Better)')\n",
    "axes[0].set_title('Regression Models - RMSE Comparison')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Classification\n",
    "clf_names = list(classification_results.keys())\n",
    "clf_f1 = [classification_results[m]['f1'] for m in clf_names]\n",
    "axes[1].barh(clf_names, clf_f1, color='coral')\n",
    "axes[1].set_xlabel('F1 Score (Higher is Better)')\n",
    "axes[1].set_title('Classification Models - F1 Score Comparison')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 10: FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[9] FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get best models\n",
    "best_reg_model = regression_models['Random Forest']\n",
    "best_clf_model = classification_models['Random Forest']\n",
    "\n",
    "# Train on full training set to get importance\n",
    "best_reg_model.fit(X_train_scaled, y_reg_train)\n",
    "best_clf_model.fit(X_train_scaled, y_clf_train)\n",
    "\n",
    "# Feature importance\n",
    "reg_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': best_reg_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "clf_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': best_clf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features - Regression:\")\n",
    "print(reg_importance.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Features - Classification:\")\n",
    "print(clf_importance.head(10))\n",
    "\n",
    "# Visualization: Feature Importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "top_n = 10\n",
    "reg_importance.head(top_n).sort_values('importance').plot(\n",
    "    kind='barh', x='feature', y='importance', ax=axes[0], legend=False, color='steelblue'\n",
    ")\n",
    "axes[0].set_title('Top 10 Features - Regression Model')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "clf_importance.head(top_n).sort_values('importance').plot(\n",
    "    kind='barh', x='feature', y='importance', ax=axes[1], legend=False, color='coral'\n",
    ")\n",
    "axes[1].set_title('Top 10 Features - Classification Model')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 11: SUMMARY & INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[10] SUMMARY & KEY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_reg = regression_results['Random Forest']\n",
    "best_clf = classification_results['Random Forest']\n",
    "\n",
    "print(f\"\"\"\n",
    "BEST REGRESSION MODEL: Random Forest\n",
    "  - RMSE: ${best_reg['test_rmse']:.2f}\n",
    "  - MAE: ${best_reg['test_mae']:.2f}\n",
    "  - R² Score: {best_reg['test_r2']:.4f}\n",
    "  \n",
    "BEST CLASSIFICATION MODEL: Random Forest\n",
    "  - Accuracy: {best_clf['accuracy']:.4f}\n",
    "  - F1 Score: {best_clf['f1']:.4f}\n",
    "  - ROC-AUC: {best_clf['roc_auc']:.4f}\n",
    "\n",
    "KEY FEATURES FOR PREDICTION:\n",
    "  1. {reg_importance.iloc[0]['feature']} (Importance: {reg_importance.iloc[0]['importance']:.3f})\n",
    "  2. {reg_importance.iloc[1]['feature']} (Importance: {reg_importance.iloc[1]['importance']:.3f})\n",
    "  3. {reg_importance.iloc[2]['feature']} (Importance: {reg_importance.iloc[2]['importance']:.3f})\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 2 PIPELINE COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
